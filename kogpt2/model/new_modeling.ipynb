{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"PyTorch OpenAI GPT-2 model.\"\"\"\n",
    "\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import gelu\n",
    "\n",
    "from transformers.configuration_gpt2 import GPT2Config\n",
    "from transformers.file_utils import add_start_docstrings\n",
    "from transformers.modeling_utils import Conv1D, PreTrainedModel, SequenceSummary, prune_conv1d_layer\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "GPT2_PRETRAINED_MODEL_ARCHIVE_MAP = {\n",
    "    \"gpt2\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin\",\n",
    "    \"gpt2-medium\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-pytorch_model.bin\",\n",
    "    \"gpt2-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-large-pytorch_model.bin\",\n",
    "    \"gpt2-xl\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-pytorch_model.bin\",\n",
    "    \"distilgpt2\": \"https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-pytorch_model.bin\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_tf_weights_in_gpt2(model, config, gpt2_checkpoint_path):\n",
    "  \"\"\" Load tf checkpoints in a pytorch model\n",
    "  \"\"\"\n",
    "  try:\n",
    "    import re\n",
    "    import tensorflow as tf\n",
    "  except ImportError:\n",
    "    logger.error(\n",
    "        \"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"\n",
    "        \"https://www.tensorflow.org/install/ for installation instructions.\"\n",
    "    )\n",
    "    raise\n",
    "  tf_path = os.path.abspath(gpt2_checkpoint_path)\n",
    "  logger.info(\"Converting TensorFlow checkpoint from {}\".format(tf_path))\n",
    "  # Load weights from TF model\n",
    "  init_vars = tf.train.list_variables(tf_path)\n",
    "  names = []\n",
    "  arrays = []\n",
    "  for name, shape in init_vars:\n",
    "    logger.info(\"Loading TF weight {} with shape {}\".format(name, shape))\n",
    "    array = tf.train.load_variable(tf_path, name)\n",
    "    names.append(name)\n",
    "    arrays.append(array.squeeze())\n",
    "\n",
    "  for name, array in zip(names, arrays):\n",
    "    name = name[6:]  # skip \"model/\"\n",
    "    name = name.split(\"/\")\n",
    "    pointer = model\n",
    "    for m_name in name:\n",
    "      if re.fullmatch(r\"[A-Za-z]+\\d+\", m_name):\n",
    "        scope_names = re.split(r\"(\\d+)\", m_name)\n",
    "      else:\n",
    "        scope_names = [m_name]\n",
    "      if scope_names[0] == \"w\" or scope_names[0] == \"g\":\n",
    "        pointer = getattr(pointer, \"weight\")\n",
    "      elif scope_names[0] == \"b\":\n",
    "        pointer = getattr(pointer, \"bias\")\n",
    "      elif scope_names[0] == \"wpe\" or scope_names[0] == \"wte\":\n",
    "        pointer = getattr(pointer, scope_names[0])\n",
    "        pointer = getattr(pointer, \"weight\")\n",
    "      else:\n",
    "        pointer = getattr(pointer, scope_names[0])\n",
    "      if len(scope_names) >= 2:\n",
    "        num = int(scope_names[1])\n",
    "        pointer = pointer[num]\n",
    "    try:\n",
    "      assert pointer.shape == array.shape\n",
    "    except AssertionError as e:\n",
    "      e.args += (pointer.shape, array.shape)\n",
    "      raise\n",
    "    logger.info(\"Initialize PyTorch weight {}\".format(name))\n",
    "    pointer.data = torch.from_numpy(array)\n",
    "  return model\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "  # 속성을 정의함, 입력으로 nx, n_ctx, config, scale 적용 여부를 받음\n",
    "  def __init__(self, nx, n_ctx, config, scale=False):\n",
    "    # 파이토치 클래스를 사용하기 위한 일반적인 문법\n",
    "    super().__init__()\n",
    "    # 첫번째 속성 : 객체는 output_attentions 속성에 config의 output_attentions을 담는다.\n",
    "    self.output_attentions = config.output_attentions\n",
    "    \n",
    "    # 속성 n_state에 nx를 담는다. 여기서 n_state는 768차원이다.\n",
    "    n_state = nx  # in Attention: n_state=768 (nx=n_embd)\n",
    "    # [switch nx => n_state from Block to Attention to keep identical to TF implem]\n",
    "    # n_state를 config.n_head로 나누었을 때 나머지가 0이 되는지 확인한다.\n",
    "    assert n_state % config.n_head == 0\n",
    "    # 속성 register_buffer(\"bias\", torch.tril(768, 768), view(1,1,768,768))\n",
    "    # 레지스터버퍼 함수는 name과 tensor를 입력으로 받는다. \n",
    "    self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
    "    # n_head에 config.n_head를 담는다.\n",
    "    self.n_head = config.n_head\n",
    "    # 스플릿사이즈에 n_state 값을 담는다.\n",
    "\n",
    "    self.split_size = n_state\n",
    "    self.scale = scale\n",
    "    # c_attn의 w매트릭스는 768 * 3 , 768\n",
    "    self.c_attn = Conv1D(n_state * 3, nx)\n",
    "    # c_proj의 w매트릭스는 768, 768\n",
    "    self.c_proj = Conv1D(n_state, nx)\n",
    "    # 드랍아웃\n",
    "    self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
    "    self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
    "    # pruned_heads는 집합 형식\n",
    "    self.pruned_heads = set()\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        mask = torch.ones(self.n_head, self.split_size // self.n_head)\n",
    "        # Convert to set and emove already pruned heads\n",
    "        heads = set(heads) - self.pruned_heads\n",
    "        for head in heads:\n",
    "      # Compute how many pruned heads are before the head and move the index accordingly\n",
    "      head = head - sum(1 if h < head else 0 for h in self.pruned_heads)\n",
    "      mask[head] = 0\n",
    "    mask = mask.view(-1).contiguous().eq(1)\n",
    "    index = torch.arange(len(mask))[mask].long()\n",
    "    index_attn = torch.cat(\n",
    "        [index, index + self.split_size, index + (2 * self.split_size)])\n",
    "\n",
    "    # Prune conv1d layers\n",
    "    self.c_attn = prune_conv1d_layer(self.c_attn, index_attn, dim=1)\n",
    "    self.c_proj = prune_conv1d_layer(self.c_proj, index, dim=0)\n",
    "\n",
    "    # Update hyper params\n",
    "    self.split_size = (self.split_size // self.n_head) * \\\n",
    "        (self.n_head - len(heads))\n",
    "    self.n_head = self.n_head - len(heads)\n",
    "    self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "  # self-attenrion 함수\n",
    "  def _attn(self, q, k, v, attention_mask=None, head_mask=None):\n",
    "    w = q * k\n",
    "    # b에 bias를 담는데 적당하게 담도록 계산하는 부분 \n",
    "    b = 0.1\n",
    "    # w에 담는다. w * b - 10000 * (1 - b)\n",
    "    #w = w * b - 1e4 * (1 - b)\n",
    "\n",
    "    if attention_mask is not None:\n",
    "      # Apply the attention mask\n",
    "      w = w + attention_mask\n",
    "\n",
    "    #w = nn.Softmax(w)\n",
    "\n",
    "    # Mask heads if we want to\n",
    "    if head_mask is not None:\n",
    "      w = w * head_mask\n",
    "\n",
    "    outputs = w * v\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Attention'>\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x._attn(1, 2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "0.5\n",
      "500.0\n",
      "-497.0\n"
     ]
    }
   ],
   "source": [
    "q = 3\n",
    "k = 4\n",
    "v = 5\n",
    "b= 0.5\n",
    "w = q * k\n",
    "w = w * b\n",
    "print(w)\n",
    "p = 1e3 * (1 - b)\n",
    "print(b)\n",
    "print(p)\n",
    "output = w * b - p\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.3781,  1.1454,  0.6767,  ...,  0.3131,  0.2286, -1.3658],\n",
      "          [-0.6200, -0.2225,  0.0104,  ..., -1.4961, -0.3580, -1.0580],\n",
      "          [ 1.1362,  0.6315,  0.2823,  ...,  0.4099, -0.7750, -0.4081],\n",
      "          ...,\n",
      "          [-0.3098,  0.0504,  0.2575,  ...,  0.8729, -0.4162, -0.7146],\n",
      "          [-1.1531, -0.6457, -0.7778,  ...,  1.3726, -0.6686,  0.2975],\n",
      "          [-0.2236, -1.4529, -0.0756,  ..., -0.9635, -1.7315, -0.4358]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn([1,1,768,768])\n",
    "print(x)\n",
    "x = x.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.3781,  1.1454,  0.6767,  ...,  0.3131,  0.2286, -1.3658]],\n",
      "\n",
      "         [[-0.6200, -0.2225,  0.0104,  ..., -1.4961, -0.3580, -1.0580]],\n",
      "\n",
      "         [[ 1.1362,  0.6315,  0.2823,  ...,  0.4099, -0.7750, -0.4081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3098,  0.0504,  0.2575,  ...,  0.8729, -0.4162, -0.7146]],\n",
      "\n",
      "         [[-1.1531, -0.6457, -0.7778,  ...,  1.3726, -0.6686,  0.2975]],\n",
      "\n",
      "         [[-0.2236, -1.4529, -0.0756,  ..., -0.9635, -1.7315, -0.4358]]]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.3781,  1.1454,  0.6767,  ...,  0.3131,  0.2286, -1.3658]],\n",
      "\n",
      "         [[-0.6200, -0.2225,  0.0104,  ..., -1.4961, -0.3580, -1.0580]],\n",
      "\n",
      "         [[ 1.1362,  0.6315,  0.2823,  ...,  0.4099, -0.7750, -0.4081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3098,  0.0504,  0.2575,  ...,  0.8729, -0.4162, -0.7146]],\n",
      "\n",
      "         [[-1.1531, -0.6457, -0.7778,  ...,  1.3726, -0.6686,  0.2975]],\n",
      "\n",
      "         [[-0.2236, -1.4529, -0.0756,  ..., -0.9635, -1.7315, -0.4358]]]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 768])\n"
     ]
    }
   ],
   "source": [
    "print(new_x_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_size = x.size()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(x_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_size2 = x.size(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "x_size3 = x.size(-1)\n",
    "print(x_size3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3781,  1.1454,  0.6767,  ...,  0.3131,  0.2286, -1.3658],\n",
      "         [-0.6200, -0.2225,  0.0104,  ..., -1.4961, -0.3580, -1.0580],\n",
      "         [ 1.1362,  0.6315,  0.2823,  ...,  0.4099, -0.7750, -0.4081],\n",
      "         ...,\n",
      "         [-0.3098,  0.0504,  0.2575,  ...,  0.8729, -0.4162, -0.7146],\n",
      "         [-1.1531, -0.6457, -0.7778,  ...,  1.3726, -0.6686,  0.2975],\n",
      "         [-0.2236, -1.4529, -0.0756,  ..., -0.9635, -1.7315, -0.4358]]])\n"
     ]
    }
   ],
   "source": [
    "r = x.view(*new_x_shape)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = x.size()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 1])\n"
     ]
    }
   ],
   "source": [
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = shape + (12, x.size(-1) // 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 1, 12, 64])\n"
     ]
    }
   ],
   "source": [
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x.view(*new_x_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3781,  1.1454,  0.6767,  ...,  0.3131,  0.2286, -1.3658],\n",
      "         [-0.6200, -0.2225,  0.0104,  ..., -1.4961, -0.3580, -1.0580],\n",
      "         [ 1.1362,  0.6315,  0.2823,  ...,  0.4099, -0.7750, -0.4081],\n",
      "         ...,\n",
      "         [-0.3098,  0.0504,  0.2575,  ...,  0.8729, -0.4162, -0.7146],\n",
      "         [-1.1531, -0.6457, -0.7778,  ...,  1.3726, -0.6686,  0.2975],\n",
      "         [-0.2236, -1.4529, -0.0756,  ..., -0.9635, -1.7315, -0.4358]]])\n",
      "torch.Size([1, 768, 768])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = x.permute(2, 0, 1)\n",
    "x_y = x.permute(2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3781, -0.6200,  1.1362,  ..., -0.3098, -1.1531, -0.2236]],\n",
      "\n",
      "        [[ 1.1454, -0.2225,  0.6315,  ...,  0.0504, -0.6457, -1.4529]],\n",
      "\n",
      "        [[ 0.6767,  0.0104,  0.2823,  ...,  0.2575, -0.7778, -0.0756]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3131, -1.4961,  0.4099,  ...,  0.8729,  1.3726, -0.9635]],\n",
      "\n",
      "        [[ 0.2286, -0.3580, -0.7750,  ..., -0.4162, -0.6686, -1.7315]],\n",
      "\n",
      "        [[-1.3658, -1.0580, -0.4081,  ..., -0.7146,  0.2975, -0.4358]]])\n"
     ]
    }
   ],
   "source": [
    "print(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3781],\n",
      "         [-0.6200],\n",
      "         [ 1.1362],\n",
      "         ...,\n",
      "         [-0.3098],\n",
      "         [-1.1531],\n",
      "         [-0.2236]],\n",
      "\n",
      "        [[ 1.1454],\n",
      "         [-0.2225],\n",
      "         [ 0.6315],\n",
      "         ...,\n",
      "         [ 0.0504],\n",
      "         [-0.6457],\n",
      "         [-1.4529]],\n",
      "\n",
      "        [[ 0.6767],\n",
      "         [ 0.0104],\n",
      "         [ 0.2823],\n",
      "         ...,\n",
      "         [ 0.2575],\n",
      "         [-0.7778],\n",
      "         [-0.0756]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3131],\n",
      "         [-1.4961],\n",
      "         [ 0.4099],\n",
      "         ...,\n",
      "         [ 0.8729],\n",
      "         [ 1.3726],\n",
      "         [-0.9635]],\n",
      "\n",
      "        [[ 0.2286],\n",
      "         [-0.3580],\n",
      "         [-0.7750],\n",
      "         ...,\n",
      "         [-0.4162],\n",
      "         [-0.6686],\n",
      "         [-1.7315]],\n",
      "\n",
      "        [[-1.3658],\n",
      "         [-1.0580],\n",
      "         [-0.4081],\n",
      "         ...,\n",
      "         [-0.7146],\n",
      "         [ 0.2975],\n",
      "         [-0.4358]]])\n"
     ]
    }
   ],
   "source": [
    "print(x_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-933616515d42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'split' is not defined"
     ]
    }
   ],
   "source": [
    "x_s = split(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = torch.randn([2,2,4,4])\n",
    "value = torch.randn([2,2,4,4])\n",
    "present = torch.stack((key.transpose(-2, -1), value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0725, -0.1802, -0.4967, -0.2464],\n",
      "          [-0.9068,  0.4818, -0.5466,  0.2060],\n",
      "          [ 0.3689, -0.5151,  0.2059,  1.4127],\n",
      "          [-0.6065, -1.5314, -0.7181, -0.2939]],\n",
      "\n",
      "         [[-0.4473,  0.2260, -1.0767, -0.7783],\n",
      "          [-0.1643, -1.2500, -0.5112,  0.8054],\n",
      "          [-0.9644, -1.3825, -0.3951, -0.8994],\n",
      "          [-0.2397,  0.3818, -0.7722,  0.3342]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1604, -0.1998,  0.9507,  0.4245],\n",
      "          [ 0.3155, -0.8320,  0.4615,  0.9241],\n",
      "          [-0.1537, -1.5395, -0.2687, -0.1006],\n",
      "          [ 1.3486,  0.1883,  0.1001,  0.4842]],\n",
      "\n",
      "         [[-0.9200,  0.1660, -0.5125, -0.9595],\n",
      "          [-0.2118,  1.2924,  0.4168, -0.2691],\n",
      "          [ 0.4307, -0.6666, -1.0174,  1.4210],\n",
      "          [-1.9475, -0.9043,  1.0805, -1.9117]]]])\n"
     ]
    }
   ],
   "source": [
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0616, -2.3956, -0.3305,  1.0422],\n",
      "          [ 1.2706,  0.0987, -0.0407, -1.1116],\n",
      "          [-0.1327,  0.0740, -0.7086, -0.7971],\n",
      "          [ 1.0783,  0.4304,  1.3829,  0.0207]],\n",
      "\n",
      "         [[ 0.6801,  0.7327,  0.1529,  0.5038],\n",
      "          [-1.0100,  0.3607, -0.5664, -1.7524],\n",
      "          [ 0.1580,  0.0985, -2.1577,  0.4655],\n",
      "          [ 0.9390, -0.8309,  0.1500,  0.8701]]],\n",
      "\n",
      "\n",
      "        [[[-0.3441,  0.1697,  0.2136, -0.2131],\n",
      "          [-0.3742,  0.4407,  0.1253, -0.5867],\n",
      "          [-2.2655,  0.4139, -0.7282,  1.7367],\n",
      "          [ 1.0252,  0.3223, -1.0377,  1.7965]],\n",
      "\n",
      "         [[-0.0986,  1.4246, -0.6832, -0.4942],\n",
      "          [-0.3007,  0.9262, -0.5225,  1.0475],\n",
      "          [-0.5953,  0.0113, -1.0411, -0.7125],\n",
      "          [-0.7568, -0.2003,  1.0781,  0.4612]]]])\n"
     ]
    }
   ],
   "source": [
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0.0725, -0.9068,  0.3689, -0.6065],\n",
      "           [-0.1802,  0.4818, -0.5151, -1.5314],\n",
      "           [-0.4967, -0.5466,  0.2059, -0.7181],\n",
      "           [-0.2464,  0.2060,  1.4127, -0.2939]],\n",
      "\n",
      "          [[-0.4473, -0.1643, -0.9644, -0.2397],\n",
      "           [ 0.2260, -1.2500, -1.3825,  0.3818],\n",
      "           [-1.0767, -0.5112, -0.3951, -0.7722],\n",
      "           [-0.7783,  0.8054, -0.8994,  0.3342]]],\n",
      "\n",
      "\n",
      "         [[[ 2.1604,  0.3155, -0.1537,  1.3486],\n",
      "           [-0.1998, -0.8320, -1.5395,  0.1883],\n",
      "           [ 0.9507,  0.4615, -0.2687,  0.1001],\n",
      "           [ 0.4245,  0.9241, -0.1006,  0.4842]],\n",
      "\n",
      "          [[-0.9200, -0.2118,  0.4307, -1.9475],\n",
      "           [ 0.1660,  1.2924, -0.6666, -0.9043],\n",
      "           [-0.5125,  0.4168, -1.0174,  1.0805],\n",
      "           [-0.9595, -0.2691,  1.4210, -1.9117]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0616, -2.3956, -0.3305,  1.0422],\n",
      "           [ 1.2706,  0.0987, -0.0407, -1.1116],\n",
      "           [-0.1327,  0.0740, -0.7086, -0.7971],\n",
      "           [ 1.0783,  0.4304,  1.3829,  0.0207]],\n",
      "\n",
      "          [[ 0.6801,  0.7327,  0.1529,  0.5038],\n",
      "           [-1.0100,  0.3607, -0.5664, -1.7524],\n",
      "           [ 0.1580,  0.0985, -2.1577,  0.4655],\n",
      "           [ 0.9390, -0.8309,  0.1500,  0.8701]]],\n",
      "\n",
      "\n",
      "         [[[-0.3441,  0.1697,  0.2136, -0.2131],\n",
      "           [-0.3742,  0.4407,  0.1253, -0.5867],\n",
      "           [-2.2655,  0.4139, -0.7282,  1.7367],\n",
      "           [ 1.0252,  0.3223, -1.0377,  1.7965]],\n",
      "\n",
      "          [[-0.0986,  1.4246, -0.6832, -0.4942],\n",
      "           [-0.3007,  0.9262, -0.5225,  1.0475],\n",
      "           [-0.5953,  0.0113, -1.0411, -0.7125],\n",
      "           [-0.7568, -0.2003,  1.0781,  0.4612]]]]])\n"
     ]
    }
   ],
   "source": [
    "print(present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tril(torch.ones(1024,1024).view(1, 1, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1024, 1024])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python36364bitanaconda3virtualenv4cedb277abcb4afbab7ee4bdb3405649"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
